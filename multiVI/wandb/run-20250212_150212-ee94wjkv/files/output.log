LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s] kl_weight batch 0 : 0.0
 kl_weight batch 40 : 0.0
 kl_weight batch 80 : 0.0
Epoch 2/500:   0%|          | 1/500 [00:05<44:44,  5.38s/it, v_num=wjkv, train_loss_step=2.59e+4, train_loss_epoch=2.96e+4] kl_weight batch 0 : 0.019999999552965164
 kl_weight batch 40 : 0.019999999552965164
 kl_weight batch 80 : 0.019999999552965164
Epoch 3/500:   0%|          | 2/500 [00:10<43:27,  5.24s/it, v_num=wjkv, train_loss_step=2.09e+4, train_loss_epoch=2.43e+4] kl_weight batch 0 : 0.03999999910593033
 kl_weight batch 40 : 0.03999999910593033
 kl_weight batch 80 : 0.03999999910593033
Epoch 4/500:   1%|          | 3/500 [00:15<42:56,  5.18s/it, v_num=wjkv, train_loss_step=1.97e+4, train_loss_epoch=2.15e+4] kl_weight batch 0 : 0.05999999865889549
 kl_weight batch 40 : 0.05999999865889549
 kl_weight batch 80 : 0.05999999865889549
Epoch 5/500:   1%|          | 4/500 [00:20<42:57,  5.20s/it, v_num=wjkv, train_loss_step=1.75e+4, train_loss_epoch=1.96e+4] kl_weight batch 0 : 0.07999999821186066
 kl_weight batch 40 : 0.07999999821186066
 kl_weight batch 80 : 0.07999999821186066
Epoch 6/500:   1%|          | 5/500 [00:25<42:23,  5.14s/it, v_num=wjkv, train_loss_step=1.79e+4, train_loss_epoch=1.83e+4] kl_weight batch 0 : 0.10000000149011612
 kl_weight batch 40 : 0.10000000149011612
 kl_weight batch 80 : 0.10000000149011612
Epoch 7/500:   1%|          | 6/500 [00:30<42:05,  5.11s/it, v_num=wjkv, train_loss_step=1.54e+4, train_loss_epoch=1.73e+4] kl_weight batch 0 : 0.11999999731779099
 kl_weight batch 40 : 0.11999999731779099
 kl_weight batch 80 : 0.11999999731779099
Epoch 8/500:   1%|▏         | 7/500 [00:36<41:59,  5.11s/it, v_num=wjkv, train_loss_step=1.48e+4, train_loss_epoch=1.65e+4] kl_weight batch 0 : 0.14000000059604645
 kl_weight batch 40 : 0.14000000059604645
 kl_weight batch 80 : 0.14000000059604645
Epoch 9/500:   2%|▏         | 8/500 [00:41<41:57,  5.12s/it, v_num=wjkv, train_loss_step=1.57e+4, train_loss_epoch=1.59e+4] kl_weight batch 0 : 0.1599999964237213
 kl_weight batch 40 : 0.1599999964237213
 kl_weight batch 80 : 0.1599999964237213
Epoch 10/500:   2%|▏         | 9/500 [00:46<41:43,  5.10s/it, v_num=wjkv, train_loss_step=1.65e+4, train_loss_epoch=1.55e+4] kl_weight batch 0 : 0.18000000715255737
 kl_weight batch 40 : 0.18000000715255737
 kl_weight batch 80 : 0.18000000715255737
Epoch 11/500:   2%|▏         | 10/500 [00:51<41:34,  5.09s/it, v_num=wjkv, train_loss_step=1.72e+4, train_loss_epoch=1.52e+4] kl_weight batch 0 : 0.20000000298023224
 kl_weight batch 40 : 0.20000000298023224
 kl_weight batch 80 : 0.20000000298023224
Epoch 12/500:   2%|▏         | 11/500 [00:56<41:40,  5.11s/it, v_num=wjkv, train_loss_step=1.55e+4, train_loss_epoch=1.49e+4] kl_weight batch 0 : 0.2199999988079071
 kl_weight batch 40 : 0.2199999988079071
 kl_weight batch 80 : 0.2199999988079071
Epoch 13/500:   2%|▏         | 12/500 [01:01<41:31,  5.11s/it, v_num=wjkv, train_loss_step=1.55e+4, train_loss_epoch=1.47e+4] kl_weight batch 0 : 0.23999999463558197
 kl_weight batch 40 : 0.23999999463558197
 kl_weight batch 80 : 0.23999999463558197
Epoch 14/500:   3%|▎         | 13/500 [01:06<41:19,  5.09s/it, v_num=wjkv, train_loss_step=1.4e+4, train_loss_epoch=1.46e+4] kl_weight batch 0 : 0.25999999046325684
 kl_weight batch 40 : 0.25999999046325684
 kl_weight batch 80 : 0.25999999046325684
Epoch 15/500:   3%|▎         | 14/500 [01:11<41:15,  5.09s/it, v_num=wjkv, train_loss_step=1.4e+4, train_loss_epoch=1.44e+4] kl_weight batch 0 : 0.2800000011920929
 kl_weight batch 40 : 0.2800000011920929
 kl_weight batch 80 : 0.2800000011920929
Epoch 16/500:   3%|▎         | 15/500 [01:16<41:11,  5.10s/it, v_num=wjkv, train_loss_step=1.49e+4, train_loss_epoch=1.44e+4] kl_weight batch 0 : 0.30000001192092896
 kl_weight batch 40 : 0.30000001192092896
 kl_weight batch 80 : 0.30000001192092896
Epoch 17/500:   3%|▎         | 16/500 [01:21<41:02,  5.09s/it, v_num=wjkv, train_loss_step=1.46e+4, train_loss_epoch=1.43e+4] kl_weight batch 0 : 0.3199999928474426
 kl_weight batch 40 : 0.3199999928474426
 kl_weight batch 80 : 0.3199999928474426
Epoch 18/500:   3%|▎         | 17/500 [01:27<41:00,  5.09s/it, v_num=wjkv, train_loss_step=1.5e+4, train_loss_epoch=1.42e+4] kl_weight batch 0 : 0.3400000035762787
 kl_weight batch 40 : 0.3400000035762787
 kl_weight batch 80 : 0.3400000035762787
Epoch 19/500:   4%|▎         | 18/500 [01:32<40:50,  5.08s/it, v_num=wjkv, train_loss_step=1.16e+4, train_loss_epoch=1.42e+4] kl_weight batch 0 : 0.36000001430511475
 kl_weight batch 40 : 0.36000001430511475
 kl_weight batch 80 : 0.36000001430511475
Epoch 20/500:   4%|▍         | 19/500 [01:37<40:47,  5.09s/it, v_num=wjkv, train_loss_step=1.4e+4, train_loss_epoch=1.41e+4] kl_weight batch 0 : 0.3799999952316284
 kl_weight batch 40 : 0.3799999952316284
 kl_weight batch 80 : 0.3799999952316284
Epoch 21/500:   4%|▍         | 20/500 [01:42<40:45,  5.09s/it, v_num=wjkv, train_loss_step=1.21e+4, train_loss_epoch=1.41e+4] kl_weight batch 0 : 0.4000000059604645
 kl_weight batch 40 : 0.4000000059604645
 kl_weight batch 80 : 0.4000000059604645
Epoch 22/500:   4%|▍         | 21/500 [01:47<40:42,  5.10s/it, v_num=wjkv, train_loss_step=1.46e+4, train_loss_epoch=1.4e+4] kl_weight batch 0 : 0.41999998688697815
 kl_weight batch 40 : 0.41999998688697815
 kl_weight batch 80 : 0.41999998688697815
Epoch 23/500:   4%|▍         | 22/500 [01:52<40:41,  5.11s/it, v_num=wjkv, train_loss_step=1.33e+4, train_loss_epoch=1.4e+4] kl_weight batch 0 : 0.4399999976158142
 kl_weight batch 40 : 0.4399999976158142
 kl_weight batch 80 : 0.4399999976158142
Epoch 24/500:   5%|▍         | 23/500 [01:57<40:43,  5.12s/it, v_num=wjkv, train_loss_step=1.62e+4, train_loss_epoch=1.4e+4] kl_weight batch 0 : 0.46000000834465027
 kl_weight batch 40 : 0.46000000834465027
 kl_weight batch 80 : 0.46000000834465027
Epoch 25/500:   5%|▍         | 24/500 [02:02<40:28,  5.10s/it, v_num=wjkv, train_loss_step=1.36e+4, train_loss_epoch=1.4e+4] kl_weight batch 0 : 0.47999998927116394
 kl_weight batch 40 : 0.47999998927116394
 kl_weight batch 80 : 0.47999998927116394
Epoch 26/500:   5%|▌         | 25/500 [02:07<40:30,  5.12s/it, v_num=wjkv, train_loss_step=1.35e+4, train_loss_epoch=1.39e+4] kl_weight batch 0 : 0.5
 kl_weight batch 40 : 0.5
 kl_weight batch 80 : 0.5
Epoch 27/500:   5%|▌         | 26/500 [02:13<40:28,  5.12s/it, v_num=wjkv, train_loss_step=1.3e+4, train_loss_epoch=1.39e+4] kl_weight batch 0 : 0.5199999809265137
 kl_weight batch 40 : 0.5199999809265137
 kl_weight batch 80 : 0.5199999809265137
Epoch 28/500:   5%|▌         | 27/500 [02:18<40:24,  5.13s/it, v_num=wjkv, train_loss_step=1.18e+4, train_loss_epoch=1.39e+4] kl_weight batch 0 : 0.5400000214576721
 kl_weight batch 40 : 0.5400000214576721
 kl_weight batch 80 : 0.5400000214576721
Epoch 29/500:   6%|▌         | 28/500 [02:23<40:26,  5.14s/it, v_num=wjkv, train_loss_step=1.6e+4, train_loss_epoch=1.39e+4] kl_weight batch 0 : 0.5600000023841858
 kl_weight batch 40 : 0.5600000023841858
 kl_weight batch 80 : 0.5600000023841858
Epoch 30/500:   6%|▌         | 29/500 [02:28<40:21,  5.14s/it, v_num=wjkv, train_loss_step=1.44e+4, train_loss_epoch=1.39e+4] kl_weight batch 0 : 0.5799999833106995
 kl_weight batch 40 : 0.5799999833106995
 kl_weight batch 80 : 0.5799999833106995
Epoch 31/500:   6%|▌         | 30/500 [02:33<40:58,  5.23s/it, v_num=wjkv, train_loss_step=1.41e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.6000000238418579
 kl_weight batch 40 : 0.6000000238418579
 kl_weight batch 80 : 0.6000000238418579
Epoch 32/500:   6%|▌         | 31/500 [02:39<41:47,  5.35s/it, v_num=wjkv, train_loss_step=1.49e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.6200000047683716
 kl_weight batch 40 : 0.6200000047683716
 kl_weight batch 80 : 0.6200000047683716
Epoch 33/500:   6%|▋         | 32/500 [02:45<42:24,  5.44s/it, v_num=wjkv, train_loss_step=1.3e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.6399999856948853
 kl_weight batch 40 : 0.6399999856948853
 kl_weight batch 80 : 0.6399999856948853
Epoch 34/500:   7%|▋         | 33/500 [02:50<42:48,  5.50s/it, v_num=wjkv, train_loss_step=1.41e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.6600000262260437
 kl_weight batch 40 : 0.6600000262260437
 kl_weight batch 80 : 0.6600000262260437
Epoch 35/500:   7%|▋         | 34/500 [02:56<43:05,  5.55s/it, v_num=wjkv, train_loss_step=1.53e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.6800000071525574
 kl_weight batch 40 : 0.6800000071525574
 kl_weight batch 80 : 0.6800000071525574
Epoch 36/500:   7%|▋         | 35/500 [03:02<43:20,  5.59s/it, v_num=wjkv, train_loss_step=1.59e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.699999988079071
 kl_weight batch 40 : 0.699999988079071
 kl_weight batch 80 : 0.699999988079071
Epoch 37/500:   7%|▋         | 36/500 [03:07<43:25,  5.61s/it, v_num=wjkv, train_loss_step=1.3e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.7200000286102295
 kl_weight batch 40 : 0.7200000286102295
 kl_weight batch 80 : 0.7200000286102295
Epoch 38/500:   7%|▋         | 37/500 [03:13<43:26,  5.63s/it, v_num=wjkv, train_loss_step=1.41e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.7400000095367432
 kl_weight batch 40 : 0.7400000095367432
 kl_weight batch 80 : 0.7400000095367432
Epoch 39/500:   8%|▊         | 38/500 [03:19<43:24,  5.64s/it, v_num=wjkv, train_loss_step=1.37e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.7599999904632568
 kl_weight batch 40 : 0.7599999904632568
 kl_weight batch 80 : 0.7599999904632568
Epoch 40/500:   8%|▊         | 39/500 [03:24<43:20,  5.64s/it, v_num=wjkv, train_loss_step=1.38e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.7799999713897705
 kl_weight batch 40 : 0.7799999713897705
 kl_weight batch 80 : 0.7799999713897705
Epoch 41/500:   8%|▊         | 40/500 [03:30<43:23,  5.66s/it, v_num=wjkv, train_loss_step=1.36e+4, train_loss_epoch=1.38e+4] kl_weight batch 0 : 0.800000011920929
 kl_weight batch 40 : 0.800000011920929
 kl_weight batch 80 : 0.800000011920929
Epoch 42/500:   8%|▊         | 41/500 [03:36<43:19,  5.66s/it, v_num=wjkv, train_loss_step=1.23e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.8199999928474426
 kl_weight batch 40 : 0.8199999928474426
 kl_weight batch 80 : 0.8199999928474426
Epoch 43/500:   8%|▊         | 42/500 [03:41<43:07,  5.65s/it, v_num=wjkv, train_loss_step=1.35e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.8399999737739563
 kl_weight batch 40 : 0.8399999737739563
 kl_weight batch 80 : 0.8399999737739563
Epoch 44/500:   9%|▊         | 43/500 [03:47<43:08,  5.66s/it, v_num=wjkv, train_loss_step=1.39e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.8600000143051147
 kl_weight batch 40 : 0.8600000143051147
 kl_weight batch 80 : 0.8600000143051147
Epoch 45/500:   9%|▉         | 44/500 [03:53<43:03,  5.67s/it, v_num=wjkv, train_loss_step=1.33e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.8799999952316284
 kl_weight batch 40 : 0.8799999952316284
 kl_weight batch 80 : 0.8799999952316284
Epoch 46/500:   9%|▉         | 45/500 [03:58<43:00,  5.67s/it, v_num=wjkv, train_loss_step=1.36e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.8999999761581421
 kl_weight batch 40 : 0.8999999761581421
 kl_weight batch 80 : 0.8999999761581421
Epoch 47/500:   9%|▉         | 46/500 [04:04<42:56,  5.67s/it, v_num=wjkv, train_loss_step=1.51e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.9200000166893005
 kl_weight batch 40 : 0.9200000166893005
 kl_weight batch 80 : 0.9200000166893005
Epoch 48/500:   9%|▉         | 47/500 [04:10<42:48,  5.67s/it, v_num=wjkv, train_loss_step=1.42e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.9399999976158142
 kl_weight batch 40 : 0.9399999976158142
 kl_weight batch 80 : 0.9399999976158142
Epoch 49/500:  10%|▉         | 48/500 [04:15<42:46,  5.68s/it, v_num=wjkv, train_loss_step=1.32e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.9599999785423279
 kl_weight batch 40 : 0.9599999785423279
 kl_weight batch 80 : 0.9599999785423279
Epoch 50/500:  10%|▉         | 49/500 [04:21<42:32,  5.66s/it, v_num=wjkv, train_loss_step=1.53e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 0.9800000190734863
 kl_weight batch 40 : 0.9800000190734863
 kl_weight batch 80 : 0.9800000190734863
Epoch 51/500:  10%|█         | 50/500 [04:27<42:23,  5.65s/it, v_num=wjkv, train_loss_step=1.7e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0
 kl_weight batch 40 : 1.0
 kl_weight batch 80 : 1.0
Epoch 52/500:  10%|█         | 51/500 [04:32<42:26,  5.67s/it, v_num=wjkv, train_loss_step=1.17e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0
 kl_weight batch 40 : 1.0
 kl_weight batch 80 : 1.0
Epoch 53/500:  10%|█         | 52/500 [04:38<42:15,  5.66s/it, v_num=wjkv, train_loss_step=1.38e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0
 kl_weight batch 40 : 1.0
 kl_weight batch 80 : 1.0
Epoch 54/500:  11%|█         | 53/500 [04:44<42:10,  5.66s/it, v_num=wjkv, train_loss_step=1.26e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0
 kl_weight batch 40 : 1.0
 kl_weight batch 80 : 1.0
Epoch 55/500:  11%|█         | 54/500 [04:49<42:02,  5.66s/it, v_num=wjkv, train_loss_step=1.41e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0
 kl_weight batch 40 : 1.0
 kl_weight batch 80 : 1.0
Epoch 56/500:  11%|█         | 55/500 [04:55<41:56,  5.66s/it, v_num=wjkv, train_loss_step=1.2e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0
 kl_weight batch 40 : 1.0
 kl_weight batch 80 : 1.0
Epoch 57/500:  11%|█         | 56/500 [05:01<41:45,  5.64s/it, v_num=wjkv, train_loss_step=1.29e+4, train_loss_epoch=1.37e+4] kl_weight batch 0 : 1.0

Detected KeyboardInterrupt, attempting graceful shutdown ...
/tmp/ipykernel_36459/3929091800.py:1: DeprecationWarning: `save_best` is deprecated in v1.2 and will be removed in v1.3. Please use `enable_checkpointing` instead. See https://github.com/scverse/scvi-tools/issues/2568 for more details.
  model.train(
1.0
0
50
0.0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
1.0
0
50
0.0
Epoch 2/500:   0%|          | 1/500 [00:03<28:58,  3.48s/it, v_num=wjkv, train_loss_step=1.48e+4, train_loss_epoch=1.36e+4]1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
1.0
1
50
0.0
Epoch 3/500:   0%|          | 2/500 [00:06<28:38,  3.45s/it, v_num=wjkv, train_loss_step=1.48e+4, train_loss_epoch=1.36e+4]1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
1.0
2
50
0.0
Epoch 4/500:   1%|          | 3/500 [00:10<28:15,  3.41s/it, v_num=wjkv, train_loss_step=1.46e+4, train_loss_epoch=1.36e+4]1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
1.0
3
50
0.0
Epoch 5/500:   1%|          | 4/500 [00:13<28:16,  3.42s/it, v_num=wjkv, train_loss_step=1.3e+4, train_loss_epoch=1.36e+4]1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
1.0
4
50
0.0
Epoch 6/500:   1%|          | 5/500 [00:17<28:12,  3.42s/it, v_num=wjkv, train_loss_step=1.54e+4, train_loss_epoch=1.36e+4]1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0
1.0
5
50
0.0

Detected KeyboardInterrupt, attempting graceful shutdown ...
/tmp/ipykernel_36459/3929091800.py:1: DeprecationWarning: `save_best` is deprecated in v1.2 and will be removed in v1.3. Please use `enable_checkpointing` instead. See https://github.com/scverse/scvi-tools/issues/2568 for more details.
  model.train(
0.0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
Epoch 2/500:   0%|          | 1/500 [00:03<28:02,  3.37s/it, v_num=wjkv, train_loss_step=1.31e+4, train_loss_epoch=1.36e+4]0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
Epoch 3/500:   0%|          | 2/500 [00:06<28:03,  3.38s/it, v_num=wjkv, train_loss_step=1.52e+4, train_loss_epoch=1.36e+4]0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04
0.04

Detected KeyboardInterrupt, attempting graceful shutdown ...
[34m[1mwandb[0m: [33mWARNING[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
