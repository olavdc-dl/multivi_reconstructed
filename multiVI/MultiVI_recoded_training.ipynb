{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Enable automatic reloading of module\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import scvi\n",
    "from src.data import AnnDataManager\n",
    "from src.dataloaders import AnnDataLoader\n",
    "import numpy as np\n",
    "import torch.nn\n",
    "from src.data.fields import LayerField, CategoricalObsField, NumericalObsField\n",
    "from src._multivae import MULTIVAE \n",
    "import math\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pooch\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run with scvi-tools version: 1.2.2.post2\n"
     ]
    }
   ],
   "source": [
    "scvi.settings.seed = 0\n",
    "print(\"Last run with scvi-tools version:\", scvi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6), frameon=False)\n",
    "sns.set_theme()\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "save_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "%config InlineBackend.print_figure_kwargs={\"facecolor\": \"w\"}\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(save_path: str, fname: str = \"pbmc_10k\"):\n",
    "    data_paths = pooch.retrieve(\n",
    "        url=\"https://cf.10xgenomics.com/samples/cell-arc/2.0.0/pbmc_unsorted_10k/pbmc_unsorted_10k_filtered_feature_bc_matrix.tar.gz\",\n",
    "        known_hash=\"872b0dba467d972aa498812a857677ca7cf69050d4f9762b2cd4753b2be694a1\",\n",
    "        fname=fname,\n",
    "        path=save_path,\n",
    "        processor=pooch.Untar(),\n",
    "        progressbar=True,\n",
    "    )\n",
    "    data_paths.sort()\n",
    "\n",
    "    for path in data_paths:\n",
    "        with gzip.open(path, \"rb\") as f_in:\n",
    "            with open(path.replace(\".gz\", \"\"), \"wb\") as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "    return str(Path(data_paths[0]).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://cf.10xgenomics.com/samples/cell-arc/2.0.0/pbmc_unsorted_10k/pbmc_unsorted_10k_filtered_feature_bc_matrix.tar.gz' to file '/tmp/tmpf2dcccei/pbmc_10k'.\n",
      "100%|████████████████████████████████████████| 375M/375M [00:00<00:00, 718GB/s]\n",
      "Untarring contents of '/tmp/tmpf2dcccei/pbmc_10k' to '/tmp/tmpf2dcccei/pbmc_10k.untar'\n"
     ]
    }
   ],
   "source": [
    "data_path = download_data(save_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "from src.data import read_10x_multiome\n",
    "# read multiomic data\n",
    "adata = read_10x_multiome(data_path)\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to three datasets by modality (RNA, ATAC, Multiome), and corrupt data\n",
    "# by remove some data to create single-modality data\n",
    "n = 4004\n",
    "adata_rna = adata[:n, adata.var.modality == \"Gene Expression\"].copy()\n",
    "adata_paired = adata[n : 2 * n].copy()\n",
    "adata_atac = adata[2 * n :, adata.var.modality == \"Peaks\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olavdc/github/multiVI/multiVI/src/data/_preprocessing.py:334: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  return multi_anndata.concatenate(other, join=\"outer\", batch_key=modality_key)\n",
      "/home/olavdc/github/multiVI/multiVI/src/data/_preprocessing.py:334: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  return multi_anndata.concatenate(other, join=\"outer\", batch_key=modality_key)\n"
     ]
    }
   ],
   "source": [
    "from src.data import organize_multiome_anndatas\n",
    "# We can now use the organizing method from scvi to concatenate these anndata\n",
    "adata_mvi = organize_multiome_anndatas(adata_paired, adata_rna, adata_atac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>modality</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIR1302-2HG</th>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>chr1</td>\n",
       "      <td>29553</td>\n",
       "      <td>30267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL391261.2</th>\n",
       "      <td>ENSG00000258847</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>chr14</td>\n",
       "      <td>66004522</td>\n",
       "      <td>66004523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUT8-AS1</th>\n",
       "      <td>ENSG00000276116</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>chr14</td>\n",
       "      <td>65412689</td>\n",
       "      <td>65412690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUT8</th>\n",
       "      <td>ENSG00000033170</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>chr14</td>\n",
       "      <td>65410591</td>\n",
       "      <td>65413008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL355076.2</th>\n",
       "      <td>ENSG00000258760</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>chr14</td>\n",
       "      <td>65302679</td>\n",
       "      <td>65318790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr15:101277030-101277907</th>\n",
       "      <td>chr15:101277030-101277907</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr15</td>\n",
       "      <td>101277030</td>\n",
       "      <td>101277907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr15:101257856-101258771</th>\n",
       "      <td>chr15:101257856-101258771</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr15</td>\n",
       "      <td>101257856</td>\n",
       "      <td>101258771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr15:101251516-101252373</th>\n",
       "      <td>chr15:101251516-101252373</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr15</td>\n",
       "      <td>101251516</td>\n",
       "      <td>101252373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr15:101397608-101398445</th>\n",
       "      <td>chr15:101397608-101398445</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr15</td>\n",
       "      <td>101397608</td>\n",
       "      <td>101398445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KI270713.1:36924-37836</th>\n",
       "      <td>KI270713.1:36924-37836</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>KI270713.1</td>\n",
       "      <td>36924</td>\n",
       "      <td>37836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148458 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID         modality  \\\n",
       "MIR1302-2HG                          ENSG00000243485  Gene Expression   \n",
       "AL391261.2                           ENSG00000258847  Gene Expression   \n",
       "FUT8-AS1                             ENSG00000276116  Gene Expression   \n",
       "FUT8                                 ENSG00000033170  Gene Expression   \n",
       "AL355076.2                           ENSG00000258760  Gene Expression   \n",
       "...                                              ...              ...   \n",
       "chr15:101277030-101277907  chr15:101277030-101277907            Peaks   \n",
       "chr15:101257856-101258771  chr15:101257856-101258771            Peaks   \n",
       "chr15:101251516-101252373  chr15:101251516-101252373            Peaks   \n",
       "chr15:101397608-101398445  chr15:101397608-101398445            Peaks   \n",
       "KI270713.1:36924-37836        KI270713.1:36924-37836            Peaks   \n",
       "\n",
       "                                  chr      start        end  \n",
       "MIR1302-2HG                      chr1      29553      30267  \n",
       "AL391261.2                      chr14   66004522   66004523  \n",
       "FUT8-AS1                        chr14   65412689   65412690  \n",
       "FUT8                            chr14   65410591   65413008  \n",
       "AL355076.2                      chr14   65302679   65318790  \n",
       "...                               ...        ...        ...  \n",
       "chr15:101277030-101277907       chr15  101277030  101277907  \n",
       "chr15:101257856-101258771       chr15  101257856  101258771  \n",
       "chr15:101251516-101252373       chr15  101251516  101252373  \n",
       "chr15:101397608-101398445       chr15  101397608  101398445  \n",
       "KI270713.1:36924-37836     KI270713.1      36924      37836  \n",
       "\n",
       "[148458 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi = adata_mvi[:, adata_mvi.var[\"modality\"].argsort()].copy()\n",
    "adata_mvi.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12012, 148458)\n",
      "(12012, 80878)\n"
     ]
    }
   ],
   "source": [
    "print(adata_mvi.shape)\n",
    "sc.pp.filter_genes(adata_mvi, min_cells=int(adata_mvi.shape[0] * 0.01))\n",
    "print(adata_mvi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_mvi.obs[\"_indices\"] = np.arange(adata_mvi.n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scvi_version', 'model_name', 'setup_args', 'field_registries', '_scvi_uuid'])\n"
     ]
    }
   ],
   "source": [
    "anndata_fields = [\n",
    "    LayerField(registry_key=\"x\", layer=None, is_count_data=True),\n",
    "    CategoricalObsField(registry_key=\"modality\", attr_key=\"modality\"),\n",
    "    NumericalObsField(registry_key  = \"cell_idx\", attr_key = \"_indices\" )\n",
    "]\n",
    "adata_manager = AnnDataManager(fields=anndata_fields)\n",
    "adata_manager.register_fields(adata_mvi)\n",
    "print(\n",
    "    adata_manager.registry.keys()\n",
    ")  # There is additionally a _scvi_uuid key which is used to uniquely identify AnnData objects for subsequent retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = adata_mvi.shape[0]\n",
    "train_size = 0.9\n",
    "validation_size = 0.1\n",
    "\n",
    "n_train = math.ceil(train_size * n_samples)\n",
    "n_val = n_samples - n_train\n",
    "\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "indices = np.arange(adata_manager.adata.n_obs)\n",
    "indices = random_state.permutation(indices)\n",
    "\n",
    "val_idx = indices[:n_val]\n",
    "train_idx = indices[n_val : (n_val + n_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>modality</th>\n",
       "      <th>_indices</th>\n",
       "      <th>_scvi_modality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCGCTAAAGGGCCATC-0-0</th>\n",
       "      <td>1</td>\n",
       "      <td>paired</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGCTAAAGTCTTGAA-0-0</th>\n",
       "      <td>1</td>\n",
       "      <td>paired</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGCTAAAGTTAGACC-0-0</th>\n",
       "      <td>1</td>\n",
       "      <td>paired</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGCTAAAGTTCCCAC-0-0</th>\n",
       "      <td>1</td>\n",
       "      <td>paired</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGCTAAAGTTTGCGG-0-0</th>\n",
       "      <td>1</td>\n",
       "      <td>paired</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTACGCGCA-1</th>\n",
       "      <td>1</td>\n",
       "      <td>accessibility</td>\n",
       "      <td>12007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTATTTGCC-1</th>\n",
       "      <td>1</td>\n",
       "      <td>accessibility</td>\n",
       "      <td>12008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTGATTACG-1</th>\n",
       "      <td>1</td>\n",
       "      <td>accessibility</td>\n",
       "      <td>12009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTTTCAGGA-1</th>\n",
       "      <td>1</td>\n",
       "      <td>accessibility</td>\n",
       "      <td>12010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTTTCCACG-1</th>\n",
       "      <td>1</td>\n",
       "      <td>accessibility</td>\n",
       "      <td>12011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12012 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      batch_id       modality  _indices  _scvi_modality\n",
       "barcode                                                                \n",
       "CCGCTAAAGGGCCATC-0-0         1         paired         0               2\n",
       "CCGCTAAAGTCTTGAA-0-0         1         paired         1               2\n",
       "CCGCTAAAGTTAGACC-0-0         1         paired         2               2\n",
       "CCGCTAAAGTTCCCAC-0-0         1         paired         3               2\n",
       "CCGCTAAAGTTTGCGG-0-0         1         paired         4               2\n",
       "...                        ...            ...       ...             ...\n",
       "TTTGTTGGTACGCGCA-1           1  accessibility     12007               0\n",
       "TTTGTTGGTATTTGCC-1           1  accessibility     12008               0\n",
       "TTTGTTGGTGATTACG-1           1  accessibility     12009               0\n",
       "TTTGTTGGTTTCAGGA-1           1  accessibility     12010               0\n",
       "TTTGTTGGTTTCCACG-1           1  accessibility     12011               0\n",
       "\n",
       "[12012 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500223.0\n",
      "1641645.0\n"
     ]
    }
   ],
   "source": [
    "train_adl = AnnDataLoader(adata_manager, indices = train_idx, shuffle= False, drop_last= False, batch_size=128)\n",
    "val_adl = AnnDataLoader(adata_manager, indices = val_idx, shuffle= False, drop_last= False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "n_genes = sum(adata_mvi.var.modality == \"Gene Expression\")\n",
    "n_regions =  sum(adata_mvi.var.modality == \"Peaks\")\n",
    "n_hidden = 128\n",
    "n_latent = 11\n",
    "n_epochs_kl_warmup = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olavdc/miniforge3/envs/deeplife/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MULTIVAE(\n",
       "  (z_encoder_expression): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=12446, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (var_encoder): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       "  (l_encoder_expression): ExprLibrarySizeEncoder(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=12446, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): None\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (z_decoder_expression): ExprDecoder(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): None\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (px_scale_decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=12446, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "    (px_r_decoder): Linear(in_features=128, out_features=12446, bias=True)\n",
       "    (px_dropout_decoder): Linear(in_features=128, out_features=12446, bias=True)\n",
       "  )\n",
       "  (z_encoder_accessibility): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=68432, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (var_encoder): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       "  (z_decoder_accessibility): AccDecoder(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): None\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=68432, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (l_encoder_accessibility): AccLibrarySizeEncoder(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=68432, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): None\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (z_encoder_protein): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): LeakyReLU(negative_slope=0.01)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (var_encoder): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       "  (z_decoder_pro): ProDecoder(\n",
       "    (py_fore_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (py_fore_scale_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=139, out_features=0, bias=True)\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (py_background_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=139, out_features=0, bias=True)\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): None\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (sigmoid_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (py_back_mean_log_alpha): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=139, out_features=0, bias=True)\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): None\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (py_back_mean_log_beta): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=139, out_features=0, bias=True)\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): None\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (py_back_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (Layer 1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): None\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adversarial_classifier): Classifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): FCLayers(\n",
       "        (fc_layers): Sequential(\n",
       "          (Layer 0): Sequential(\n",
       "            (0): Linear(in_features=11, out_features=32, bias=True)\n",
       "            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): None\n",
       "            (3): ReLU()\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (Layer 1): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): None\n",
       "            (3): ReLU()\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Linear(in_features=32, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multivi = MULTIVAE(\n",
    "    n_input_genes = n_genes,\n",
    "    n_input_regions = n_regions,\n",
    "    n_hidden = n_hidden,\n",
    "    n_latent = n_latent,\n",
    "    deeply_inject_covariates = True,\n",
    "    n_batch = adata_manager.summary_stats.n_modality,\n",
    "    modality_weights = \"universal\"\n",
    ")\n",
    "\n",
    "multivi.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# extract parameters of the model and adversial classifier\n",
    "model_params = [param for name, param in multivi.named_parameters() if \"adversarial_classifier\" not in name]\n",
    "adversarial_params = [param for name, param in multivi.named_parameters() if \"adversarial_classifier\" in name]\n",
    "\n",
    "model_optimizer = optim.AdamW(model_params, lr=1e-4, weight_decay=1e-3, eps = 1e-08)\n",
    "# adversarial_optimizer = optim.Adam(adversarial_params, lr=1e-3, eps=0.01, weight_decay=self.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_kl_weight(\n",
    "    epoch: int,\n",
    "    n_epochs_kl_warmup: int | None,\n",
    "    max_kl_weight: float = 1.0,\n",
    "    min_kl_weight: float = 0.0,\n",
    ") -> float | torch.Tensor:\n",
    "    \"\"\"Computes the kl weight for the current step or epoch.\n",
    "\n",
    "    If both `n_epochs_kl_warmup` and `n_steps_kl_warmup` are None `max_kl_weight` is returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch\n",
    "        Current epoch.\n",
    "    step\n",
    "        Current step.\n",
    "    n_epochs_kl_warmup\n",
    "        Number of training epochs to scale weight on KL divergences from\n",
    "        `min_kl_weight` to `max_kl_weight`\n",
    "    n_steps_kl_warmup\n",
    "        Number of training steps (minibatches) to scale weight on KL divergences from\n",
    "        `min_kl_weight` to `max_kl_weight`\n",
    "    max_kl_weight\n",
    "        Maximum scaling factor on KL divergence during training.\n",
    "    min_kl_weight\n",
    "        Minimum scaling factor on KL divergence during training.\n",
    "    \"\"\"\n",
    "    if min_kl_weight > max_kl_weight:\n",
    "        raise ValueError(\n",
    "            f\"min_kl_weight={min_kl_weight} is larger than max_kl_weight={max_kl_weight}.\"\n",
    "        )\n",
    "\n",
    "    slope = max_kl_weight - min_kl_weight\n",
    "    if n_epochs_kl_warmup:\n",
    "        if epoch < n_epochs_kl_warmup:\n",
    "            return slope * (epoch / n_epochs_kl_warmup) + min_kl_weight\n",
    "    elif n_steps_kl_warmup:\n",
    "        if step < n_steps_kl_warmup:\n",
    "            return slope * (step / n_steps_kl_warmup) + min_kl_weight\n",
    "    return max_kl_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [2.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     73\u001b[0m model_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 75\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loss_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"adv_train_loss\": adv_loss.detach(),\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"kl_local_train\" : kl_local_loss.detach(),\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m batch_model_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     83\u001b[0m batch_kl_local_losses\u001b[38;5;241m.\u001b[39mappend(kl_local_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/miniforge3/envs/deeplife/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"multiVI-training\")\n",
    "\n",
    "epoch_model_losses = []\n",
    "epoch_adv_losses = []\n",
    "epoch_kl_local_train = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training \n",
    "\n",
    "    multivi.train()\n",
    "    batch_model_losses = []\n",
    "    batch_adv_losses = []\n",
    "    batch_kl_local_losses = []\n",
    "    batch_recon_losses = []\n",
    "\n",
    "    for i, batch in enumerate(train_adl):\n",
    "\n",
    "        x = batch[\"x\"].to(device)\n",
    "        modality = batch[\"modality\"].to(device)\n",
    "        cell_idx = batch[\"cell_idx\"].to(device)       \n",
    "        y = torch.zeros(x.shape[0], 1, device=x.device, requires_grad=False).to(device) # in case of no usage of porteins \n",
    "\n",
    "        print(modality)\n",
    "\n",
    "        # print(f\"x batch {i} : {x.sum()}\")\n",
    "            \n",
    "        # inference\n",
    "        inference_outputs = multivi.inference(x, y, modality, cell_idx)\n",
    "\n",
    "        latent = inference_outputs[\"z\"]\n",
    "        libsize_expr = inference_outputs[\"libsize_expr\"]\n",
    "        libsize_acc = inference_outputs[\"libsize_acc\"]\n",
    "    \n",
    "        # generation\n",
    "        generative_outputs = multivi.generative(latent,modality,libsize_expr)\n",
    "\n",
    "        # kl_weight & kappa\n",
    "        klw = _compute_kl_weight(\n",
    "            epoch = epoch,\n",
    "            n_epochs_kl_warmup = n_epochs_kl_warmup,\n",
    "            min_kl_weight=1e-3            \n",
    "        )\n",
    "\n",
    "        kappa = 1 \n",
    "\n",
    "        # loss\n",
    "        loss, kl_local_loss, recon_loss = multivi.loss(\n",
    "            inference_outputs,\n",
    "            generative_outputs,\n",
    "            klw\n",
    "        )\n",
    "        \n",
    "        n_obs_in_batch = len(kl_local_loss[\"kl_divergence_z\"])\n",
    "        kl_local_loss = (sum(kl_local_loss.values()).sum())/n_obs_in_batch\n",
    "        recon_loss = (sum(recon_loss.values()).sum())/n_obs_in_batch\n",
    "\n",
    "        # # fool classifier by modifying z\n",
    "        # fool_loss = multivi.loss_adversarial_classifier(latent, modality, False)\n",
    "        # model_loss = loss + (fool_loss * kappa)\n",
    "        # model_optimizer.zero_grad()        \n",
    "        # model_loss.backward()\n",
    "        # model_optimizer.step()\n",
    "\n",
    "        # # train classifier\n",
    "        # adv_loss = multivi.loss_adversarial_classifier(latent.detach(), modality, True)\n",
    "        # adv_loss *= kappa\n",
    "        # adversarial_optimizer.zero_grad()\n",
    "        # adv_loss.backward()\n",
    "        # adversarial_optimizer.step()\n",
    "\n",
    "        model_optimizer.zero_grad()        \n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "\n",
    "        wandb.log({\n",
    "            \"train_loss_step\": loss.detach(),\n",
    "            # \"adv_train_loss\": adv_loss.detach(),\n",
    "            # \"kl_local_train\" : kl_local_loss.detach(),\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "        \n",
    "        batch_model_losses.append(loss.detach().cpu())\n",
    "        batch_kl_local_losses.append(kl_local_loss.detach().cpu())\n",
    "        batch_recon_losses.append(recon_loss.detach().cpu())\n",
    "    \n",
    "    epoch_model_loss = np.mean(batch_model_losses)\n",
    "    epoch_kl_local_train = np.mean(batch_kl_local_losses)\n",
    "    epoch_recon_loss = np.mean(batch_recon_losses)\n",
    "\n",
    "    wandb.log({\n",
    "    \"train_loss_epoch\": epoch_model_loss,\n",
    "    \"kl_local_train\" : epoch_kl_local_train,\n",
    "    \"reconstruction_loss_train\": epoch_recon_loss, \n",
    "    \"epoch\": epoch\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiVI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
