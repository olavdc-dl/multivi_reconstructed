{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Enable automatic reloading of modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/olav/Documents/PhD/scvi-tools/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/multiVI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "from scvi.data import AnnDataManager\n",
    "from scvi.dataloaders import AnnDataLoader\n",
    "import numpy as np\n",
    "import torch.nn\n",
    "\n",
    "import scvi_local\n",
    "\n",
    "from scvi_local.nn import DecoderSCVI, Encoder, FCLayers\n",
    "\n",
    "from scvi.data import AnnDataManager\n",
    "from scvi.data.fields import LayerField, CategoricalObsField, NumericalObsField\n",
    "from src._multivae import MULTIVAE \n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pooch\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(\"/Users/olav/Documents/PhD/multiVI/data/mixed_source_adata.h5ad.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to three datasets by modality (RNA, ATAC, Multiome), and corrupt data\n",
    "# by remove some data to create single-modality data\n",
    "n = 4004\n",
    "adata_rna = adata[:n, adata.var.modality == \"Gene Expression\"].copy()\n",
    "adata_paired = adata[n : 2 * n].copy()\n",
    "adata_atac = adata[2 * n :, adata.var.modality == \"Peaks\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olav/Documents/PhD/scvi-tools/src/scvi_local/data/_preprocessing.py:334: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  return multi_anndata.concatenate(other, join=\"outer\", batch_key=modality_key)\n",
      "/Users/olav/Documents/PhD/scvi-tools/src/scvi_local/data/_preprocessing.py:334: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  return multi_anndata.concatenate(other, join=\"outer\", batch_key=modality_key)\n"
     ]
    }
   ],
   "source": [
    "adata_mvi = scvi_local.data.organize_multiome_anndatas(adata_paired, adata_rna, adata_atac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>modality</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>n_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1BG</th>\n",
       "      <td>A1BG</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAI1</th>\n",
       "      <td>RAI1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAF1</th>\n",
       "      <td>RAF1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAE1</th>\n",
       "      <td>RAE1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD9A</th>\n",
       "      <td>RAD9A</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr17:79840351-79840851</th>\n",
       "      <td>chr17:79840351-79840851</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr17</td>\n",
       "      <td>79840351</td>\n",
       "      <td>79840851</td>\n",
       "      <td>2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr17:79838639-79839139</th>\n",
       "      <td>chr17:79838639-79839139</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr17</td>\n",
       "      <td>79838639</td>\n",
       "      <td>79839139</td>\n",
       "      <td>8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr17:79837846-79838346</th>\n",
       "      <td>chr17:79837846-79838346</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr17</td>\n",
       "      <td>79837846</td>\n",
       "      <td>79838346</td>\n",
       "      <td>3831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr17:79836519-79837019</th>\n",
       "      <td>chr17:79836519-79837019</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chr17</td>\n",
       "      <td>79836519</td>\n",
       "      <td>79837019</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:9995706-9996206</th>\n",
       "      <td>chrX:9995706-9996206</td>\n",
       "      <td>Peaks</td>\n",
       "      <td>chrX</td>\n",
       "      <td>9995706</td>\n",
       "      <td>9996206</td>\n",
       "      <td>3104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94507 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         feature         modality    chr  \\\n",
       "A1BG                                        A1BG  Gene Expression    NaN   \n",
       "RAI1                                        RAI1  Gene Expression    NaN   \n",
       "RAF1                                        RAF1  Gene Expression    NaN   \n",
       "RAE1                                        RAE1  Gene Expression    NaN   \n",
       "RAD9A                                      RAD9A  Gene Expression    NaN   \n",
       "...                                          ...              ...    ...   \n",
       "chr17:79840351-79840851  chr17:79840351-79840851            Peaks  chr17   \n",
       "chr17:79838639-79839139  chr17:79838639-79839139            Peaks  chr17   \n",
       "chr17:79837846-79838346  chr17:79837846-79838346            Peaks  chr17   \n",
       "chr17:79836519-79837019  chr17:79836519-79837019            Peaks  chr17   \n",
       "chrX:9995706-9996206        chrX:9995706-9996206            Peaks   chrX   \n",
       "\n",
       "                            start       end  n_cells  \n",
       "A1BG                          NaN       NaN     2244  \n",
       "RAI1                          NaN       NaN     2053  \n",
       "RAF1                          NaN       NaN     8408  \n",
       "RAE1                          NaN       NaN     2274  \n",
       "RAD9A                         NaN       NaN     2844  \n",
       "...                           ...       ...      ...  \n",
       "chr17:79840351-79840851  79840351  79840851     2844  \n",
       "chr17:79838639-79839139  79838639  79839139     8532  \n",
       "chr17:79837846-79838346  79837846  79838346     3831  \n",
       "chr17:79836519-79837019  79836519  79837019     3576  \n",
       "chrX:9995706-9996206      9995706   9996206     3104  \n",
       "\n",
       "[94507 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi = adata_mvi[:, adata_mvi.var[\"modality\"].argsort()].copy()\n",
    "adata_mvi.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 89655 × 94507\n",
       "    obs: 'barcode', 'source', 'rep', 'tech', 'celltype', '_scvi_batch', '_scvi_labels', '_scvi_local_l_mean', '_scvi_local_l_var', 'modality'\n",
       "    var: 'feature', 'modality', 'chr', 'start', 'end', 'n_cells'\n",
       "    obsm: 'X_multiVI', 'X_multiVI_nbc', 'X_umap', '_scvi_extra_categoricals'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_mvi = adata_mvi[adata_mvi.obs.modality == \"accessibility\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/6p6w73m17v30g7yj23swh9vm0000gn/T/ipykernel_29606/1202738452.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata_mvi.obs[\"_indices\"] = np.arange(adata_mvi.n_obs)\n"
     ]
    }
   ],
   "source": [
    "adata_mvi.obs[\"_indices\"] = np.arange(adata_mvi.n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scvi_version', 'model_name', 'setup_args', 'field_registries', '_scvi_uuid'])\n"
     ]
    }
   ],
   "source": [
    "anndata_fields = [\n",
    "    LayerField(registry_key=\"x\", layer=None, is_count_data=True),\n",
    "    CategoricalObsField(registry_key=\"modality\", attr_key=\"modality\"),\n",
    "    NumericalObsField(registry_key  = \"cell_idx\", attr_key = \"_indices\" )\n",
    "]\n",
    "adata_manager = AnnDataManager(fields=anndata_fields)\n",
    "adata_manager.register_fields(adata_mvi)\n",
    "print(\n",
    "    adata_manager.registry.keys()\n",
    ")  # There is additionally a _scvi_uuid key which is used to uniquely identify AnnData objects for subsequent retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "adl = AnnDataLoader(adata_manager, shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "n_genes = sum(adata_mvi.var.modality == \"Gene Expression\")\n",
    "n_regions =  sum(adata_mvi.var.modality == \"Peaks\")\n",
    "n_hidden = 128\n",
    "n_latent = 10\n",
    "n_epochs_kl_warmup = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivi = MULTIVAE(\n",
    "    n_input_genes = n_genes,\n",
    "    n_input_regions = n_regions,\n",
    "    n_hidden = n_hidden,\n",
    "    n_latent = n_latent,\n",
    "    deeply_inject_covariates = True,\n",
    "    n_batch = adata_manager.summary_stats.n_modality,\n",
    "    modality_weights = \"universal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# extract parameters of the model and adversial classifier\n",
    "model_params = [param for name, param in multivi.named_parameters() if \"adversarial_classifier\" not in name]\n",
    "adversarial_params = [param for name, param in multivi.named_parameters() if \"adversarial_classifier\" in name]\n",
    "\n",
    "model_optimizer = optim.Adam(model_params, lr=0.0001,weight_decay=0.001)\n",
    "adversarial_optimizer = optim.Adam(adversarial_params, lr=0.0001,weight_decay=1e-6, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_kl_weight(\n",
    "    epoch: int,\n",
    "    n_epochs_kl_warmup: int | None,\n",
    "    max_kl_weight: float = 1.0,\n",
    "    min_kl_weight: float = 0.0,\n",
    ") -> float | torch.Tensor:\n",
    "    \"\"\"Computes the kl weight for the current step or epoch.\n",
    "\n",
    "    If both `n_epochs_kl_warmup` and `n_steps_kl_warmup` are None `max_kl_weight` is returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch\n",
    "        Current epoch.\n",
    "    step\n",
    "        Current step.\n",
    "    n_epochs_kl_warmup\n",
    "        Number of training epochs to scale weight on KL divergences from\n",
    "        `min_kl_weight` to `max_kl_weight`\n",
    "    n_steps_kl_warmup\n",
    "        Number of training steps (minibatches) to scale weight on KL divergences from\n",
    "        `min_kl_weight` to `max_kl_weight`\n",
    "    max_kl_weight\n",
    "        Maximum scaling factor on KL divergence during training.\n",
    "    min_kl_weight\n",
    "        Minimum scaling factor on KL divergence during training.\n",
    "    \"\"\"\n",
    "    if min_kl_weight > max_kl_weight:\n",
    "        raise ValueError(\n",
    "            f\"min_kl_weight={min_kl_weight} is larger than max_kl_weight={max_kl_weight}.\"\n",
    "        )\n",
    "\n",
    "    slope = max_kl_weight - min_kl_weight\n",
    "    if n_epochs_kl_warmup:\n",
    "        if epoch < n_epochs_kl_warmup:\n",
    "            return slope * (epoch / n_epochs_kl_warmup) + min_kl_weight\n",
    "    elif n_steps_kl_warmup:\n",
    "        if step < n_steps_kl_warmup:\n",
    "            return slope * (step / n_steps_kl_warmup) + min_kl_weight\n",
    "    return max_kl_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (16, 10)) of distribution Normal(loc: torch.Size([16, 10]), scale: torch.Size([16, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n       grad_fn=<AddmmBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m cell_idx \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m]       \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# y = torch.zeros(x.shape[0], 1, device=x.device, requires_grad=False) # in case of no usage of porteins \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# inference\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m inference_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmultivi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m latent \u001b[38;5;241m=\u001b[39m inference_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m libsize_expr \u001b[38;5;241m=\u001b[39m inference_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibsize_expr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/PhD/multiVI/src/_multivae.py:258\u001b[0m, in \u001b[0;36mMULTIVAE.inference\u001b[0;34m(self, x, batch_index, cell_idx, cat_covs, cont_covs)\u001b[0m\n\u001b[1;32m    255\u001b[0m encoder_input_expression \u001b[38;5;241m=\u001b[39m x_rna\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Z Encoders\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m qzm_acc, qzv_acc, z_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_encoder_accessibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_input_accessibility\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcategorical_input\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m qzm_expr, qzv_expr, z_expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_encoder_expression(\n\u001b[1;32m    262\u001b[0m     encoder_input_expression, batch_index, \u001b[38;5;241m*\u001b[39mcategorical_input\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# L encoders\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multiVI/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multiVI/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/PhD/multiVI/src/_base_components.py:172\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, *cat_list)\u001b[0m\n\u001b[1;32m    170\u001b[0m q_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_encoder(q)\n\u001b[1;32m    171\u001b[0m q_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_activation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_encoder(q)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_eps\n\u001b[0;32m--> 172\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_transformation(dist\u001b[38;5;241m.\u001b[39mrsample())\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_m, q_v, latent\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multiVI/lib/python3.10/site-packages/torch/distributions/normal.py:59\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/multiVI/lib/python3.10/site-packages/torch/distributions/distribution.py:71\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     69\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 71\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (16, 10)) of distribution Normal(loc: torch.Size([16, 10]), scale: torch.Size([16, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n       grad_fn=<AddmmBackward0>)"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    multivi.train()\n",
    "    batch_losses = []\n",
    "\n",
    "    for i, batch in enumerate(adl):\n",
    "\n",
    "        x = batch[\"x\"]\n",
    "        modality = batch[\"modality\"]\n",
    "        cell_idx = batch[\"cell_idx\"]       \n",
    "        # y = torch.zeros(x.shape[0], 1, device=x.device, requires_grad=False) # in case of no usage of porteins \n",
    "\n",
    "        # inference\n",
    "        inference_outputs = multivi.inference(x, modality, cell_idx)\n",
    "\n",
    "        latent = inference_outputs[\"z\"]\n",
    "        libsize_expr = inference_outputs[\"libsize_expr\"]\n",
    "        libsize_acc = inference_outputs[\"libsize_acc\"]\n",
    "\n",
    "        # generation\n",
    "        generative_outputs = multivi.generative(latent,modality,libsize_expr)\n",
    "\n",
    "        # kl_weight & kappa\n",
    "        klw = _compute_kl_weight(\n",
    "            epoch = epoch,\n",
    "            n_epochs_kl_warmup = n_epochs_kl_warmup            \n",
    "        )\n",
    "        kappa = 1 - klw\n",
    "\n",
    "        # loss\n",
    "        loss = multivi.loss(\n",
    "            inference_outputs,\n",
    "            generative_outputs,\n",
    "            klw\n",
    "        )\n",
    "\n",
    "        # fool classifier by modifying z\n",
    "        fool_loss = multivi.loss_adversarial_classifier(latent, modality, False)\n",
    "        model_loss = loss + (fool_loss * kappa)\n",
    "        model_optimizer.zero_grad()        \n",
    "        model_loss.backward()\n",
    "        model_optimizer.step()\n",
    "\n",
    "        # train classifier\n",
    "        adv_loss = multivi.loss_adversarial_classifier(latent.detach(), modality, True)\n",
    "        adv_loss *= kappa\n",
    "        adversarial_optimizer.zero_grad()\n",
    "        adv_loss.backward()\n",
    "        adversarial_optimizer.step()\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"batch nr {i} loss : {loss}\")\n",
    "            \n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(f\"epoch loss : {epoch_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiVI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
